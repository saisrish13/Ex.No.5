# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

# Aim: To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

### AI Tools Required: 

# Explanation: 
Define the Two Prompt Types:

Write a basic Prompt: Clear, detailed, and structured prompts that give specific instructions or context to guide the model.
Based on that pattern type refined the prompt and submit that with AI tool.
Get the ouput and write the report.

Prepare Multiple Test Scenarios:
Select various scenarios such as:
Generating a creative story.
Answering a factual question.
Summarizing an article or concept.
Providing advice or recommendations.
Or Any other test scenario
For each scenario, create both a naïve and a basic prompt. Ensure each pair of prompts targets the same task but with different levels of structure.
Run Experiments with ChatGPT:
Input the naïve prompt for each scenario and record the generated response.
Then input the corresponding basic prompt and capture that response.
Repeat this process for all selected scenarios to gather a full set of results.
Evaluate Responses : 
	Compare how ChatGPT performs when given naïve versus basic prompts and analyze the output based on Quality,Accuracy and Depth. Also analyse does ChatGPT consistently provide better results with basic prompts? Are there scenarios where naïve prompts work equally well?
Deliverables:
A table comparing ChatGPT's responses to naïve and basic prompts across all scenarios.
Analysis of how prompt clarity impacts the quality, accuracy, and depth of ChatGPT’s outputs.
Summary of findings with insights on how to structure prompts for optimal results when using ChatGPT.

AI TOOLS REQUIRED:
- ChatGPT (GPT-5)
- Internet-enabled computer or laptop
EXPLANATION:
In this experiment, we examine how ChatGPT performs when given prompts with different clarity levels. Two prompt types are defined — naïve (broad/unstructured) and basic (clear/refined). Multiple test scenarios are created to evaluate ChatGPT’s response in terms of quality, accuracy, and depth.
Definition of Prompt Types:
Prompt Type	Description	Example
Naïve Prompt	Broad, unclear, and unstructured; gives little context or direction.	Write about space.
Basic (Refined) Prompt	Clear, structured, and detailed; provides specific context or output format.	Write a 100-word creative story about an astronaut who discovers a new planet made entirely of ice.
Test Scenarios and Prompts:
Scenario	Naïve Prompt	Basic (Refined) Prompt
Creative Story Generation	Write a story.	Write a short, imaginative story (around 150 words) about a robot that learns to feel emotions.
Factual Question Answering	Tell me about AI.	Explain Artificial Intelligence in 100 words — include its definition, applications, and one example.
Summarization Task	Summarize the Internet.	Summarize the importance and impact of the Internet on communication and education in 5 points.
Providing Advice	Give me some advice.	Provide 3 useful tips for students to improve concentration while studying for exams.
Concept Explanation	Explain blockchain.	Explain blockchain technology in simple terms with one real-world example of its use.
Experimental Results and Comparison:
Scenario	Naïve Prompt Output Summary	Basic Prompt Output Summary	Analysis (Quality, Accuracy, Depth)
Creative Story	Generic story; lacks focus.	Structured story with emotional depth.	Basic prompt produces coherent and engaging output.
Factual Question	Vague and mixed facts.	Organized with clear examples.	Basic prompt yields higher factual accuracy.
Summarization	Rambling and incomplete.	Concise and well-structured.	Basic prompt improves clarity and relevance.
Advice	Generic life advice.	Study-specific and practical.	Basic prompt enhances usefulness and focus.
Concept Explanation	Too technical.	Simple with real-world example.	Basic prompt increases comprehension.
Evaluation Metrics:
Criteria	Naïve Prompt (Avg Score)	Basic Prompt (Avg Score)
Quality	6 / 10	9 / 10
Accuracy	7 / 10	9 / 10
Depth	5 / 10	8 / 10
ANALYSIS:
The results show that ChatGPT performs significantly better with structured and refined prompts. Naïve prompts often lead to vague, incomplete, or off-topic responses. In contrast, basic prompts guide the model effectively, producing more accurate and context-aware answers. Creative tasks can still yield decent results from naïve prompts, but technical or factual tasks benefit strongly from structured instructions.
SUMMARY OF FINDINGS:
- Clear, detailed prompts lead to higher quality, organization, and relevance.
- Naïve prompts work only for open-ended creative scenarios.
- Structured prompts improve both factual accuracy and user satisfaction.
- For optimal results, prompts should include context, constraints, and examples.



# OUTPUT
[Prompt_Testing_and_Evaluation_Report.pdf](https://github.com/user-attachments/files/23021035/Prompt_Testing_and_Evaluation_Report.pdf)

# RESULT: The prompt for the above said problem executed successfully
